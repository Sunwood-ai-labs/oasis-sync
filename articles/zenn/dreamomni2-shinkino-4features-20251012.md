---
title: 画像生成AIの常識が変わる？話題の「DreamOmni 2」の驚くべき4つの新機能
emoji: 🪄
type: tech
topics:
- ai
- image-generation
- dreamomni
- multimodal
- creativity
published: true
---

「このキャラクターのまま、違うポーズや服装の画像を生成したい」「この写真の素敵な雰囲気を、別の写真に適用できないだろうか？」 画像生成AIを使ったことがある人なら、一度はこんな風に思ったことがあるのではないでしょうか。テキストだけで微妙なニュアンスを伝えるのは難しく、思い通りの結果を得るために試行錯誤を繰り返すことも少なくありません。

そんな私たちの悩みを解決してくれるかもしれない、画期的なAIが登場しました。香港中文大学、香港科技大学、そしてByteDanceの研究者が開発した最新のマルチモーダル生成モデル「DreamOmni 2」です。

この記事では、DreamOmni 2が持つ数々の機能の中から、特に私たちのクリエイティブな活動を根底から変えてしまいそうな、驚くべき4つの新機能に絞って分かりやすく解説していきます。

## 1. 指示は「テキスト＋お手本画像」の新時代へ

従来の画像生成AIは、そのほとんどがテキストによる指示（プロンプト）に依存していました。そのため、「ざらっとした質感」や「特定のデザイン」といった、言葉では表現しきれない視覚的なニュアンスを正確に伝えるのが非常に困難でした。

DreamOmni 2は、この課題を「マルチモーダル指示」というアプローチで解決します。これは、テキストとお手本画像の両方を指示として使える機能です。これにより、「このジャケットを着た人物を生成して[テキスト指示]、この絵画の芸術スタイルを使って[画像指示]」というように、言語的な命令と視覚的な見本を組み合わせた、極めて具体的な指示が可能になったのです。この柔軟なアプローチは、既存の画像の一部を修正する「編集」タスクと、参照画像の特性を受け継いで全く新しい画像を創り出す「生成」タスクの両方に応用できます。

研究者の技術報告書では、この核心的なコンセプトが次のように述べられています。

> 本モデルはテキストと例示画像の両方を指示として扱う マルチモーダル指示に基づく編集と生成 を導入しています。これにより、ユーザーは素材・質感・芸術スタイルなどの抽象的な概念だけでなく、具体的な物体を利用して編集や生成を制御できます。

## 2. たった1枚の写真から「同じキャラクター」を自由自在に生成

これまでのAIモデルで、同じキャラクターを様々なシーンやポーズで登場させるには、そのキャラクターの画像を何枚も用意し、モデルを微調整（ファインチューニング）するという、時間と手間のかかる作業が必要でした。

DreamOmni 2は、このプロセスを劇的に簡略化します。たった1枚の参照画像さえあれば、モデルがそのキャラクターのアイデンティティだけでなく、姿勢や髪型といった抽象的な属性まで理解し、全く異なる背景やシーンの中でも一貫性を保ったまま新しい画像を生成できるのです。

この機能は、GitHubの報告によれば「優れた人物識別およびポーズの一貫性」を実現しており、これまで難しかった「シーンをまたいだキャラクターの一貫性」という課題に対する強力なソリューションとなります。

## 3. 複数の画像を組み合わせる「魔法のような編集」

DreamOmni 2の真骨頂の一つが、複数の参照画像を同時に扱える「マルチイメージ編集」機能です。これは、単一の参照画像から特徴を抽出するだけにとどまりません。

従来のモデルでは、複数の参照画像からの視覚情報を同時に入力すると情報が混同してしまうという課題がありました。DreamOmni 2は、この課題を「インデックス符号化」と「位置符号化のシフト方式」という技術で解決しています。これらの手法により、モデルは複数の画像から送られてくる情報を混同することなく、それぞれの特徴を正確に区別して処理することができます。

具体的には、**「1枚目の画像の人物を、2枚目の画像の人物に置き換え、さらに3枚目の画像の光の条件を適用する」**といった、まるで魔法のような複雑な編集が指示一つで可能になります。実際に、AIプラットフォームのfal.aiでは、「1枚目の画像を差し替え、2枚目の画像と同じスタイルにする」といったプロンプトを試すことができます。

## 4. 色合いだけじゃない。「芸術スタイル」を丸ごと転送

DreamOmni 2には、「美的スタイル転送」という驚くべき機能も搭載されています。これは、単に写真の色味を別の写真に合わせるといったレベルの話ではありません。

この機能を使えば、参照画像が持つ**「質感」「素材感」「メイクアップ」「芸術的なスタイル」といった、より抽象的で複雑な属性を丸ごと抽出し、別の画像に適用**することができるのです。素晴らしいのは、元の画像の構成要素はそのまま維持しつつ、参照画像の持つ独特の雰囲気だけを精密にまとわせることができる点です。

この機能は、ビジュアルストーリーテリングやブランディング、クリエイティブデザインの分野において、一貫した世界観を持つコンテンツを効率的に制作するための強力な武器となるでしょう。これまでにない新しい表現の可能性が広がります。

## 5. まとめ：編集と生成の垣根を越えるAI

今回ご紹介した4つの機能は、DreamOmni 2の可能性のほんの一部に過ぎません。

1. テキスト＋お手本画像による直感的な指示  
2. 1枚の画像からのキャラクター一貫性維持  
3. 複数画像の組み合わせによる高度な編集  
4. 芸術スタイルの丸ごと転送  

これらの機能から分かるように、DreamOmni 2は単なる画像「生成」ツールではありません。「編集」と「生成」をシームレスに統合し、私たちの意図をより深く理解してくれる、汎用的な視覚AIシステムへの重要な一歩と言えるでしょう。

このモデルはApache-2.0ライセンスで公開されており、fal.aiのようなプラットフォームを通じて既に誰でも利用可能です。

このようなツールが当たり前になった未来で、私たちのクリエイティビティはどのように変化していくのでしょうか？ DreamOmni 2は、その答えを考える上で、非常に重要な示唆を与えてくれています。
